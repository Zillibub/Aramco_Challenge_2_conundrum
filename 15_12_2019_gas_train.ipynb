{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train = pd.read_csv('Geochemistry Data/CNS_gas_train.csv').reset_index(drop=True)\n",
    "gas_train_cols_desc = df_gas_train.loc[0].values.tolist()\n",
    "df_gas_train = df_gas_train[1:].reset_index(drop=True)\n",
    "df_gas_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df_gas_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLS = ['GAS_C1', 'GAS_C2', 'GAS_C3', 'GAS_IC4', 'GAS_NC4', 'GAS_IC5', 'GAS_NC5']\n",
    "\n",
    "gas_f = ['GAS_C1',\n",
    "         'GAS_C2',\n",
    "         'C2_UNSAT',\n",
    "         'GAS_C3',\n",
    "         'C3_UNSAT',\n",
    "         'GAS_IC4',\n",
    "         'GAS_NC4',\n",
    "         'C4_UNSAT',\n",
    "         'GAS_NEOC5',\n",
    "         'GAS_IC5',\n",
    "         'GAS_NC5',\n",
    "         'C5_UNSAT',\n",
    "         'GAS_NC5_PLUS',\n",
    "         'GAS_C6PLUS',\n",
    "         'GAS_O2',\n",
    "         'GAS_CO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['WH_WATER_DEPTH_M'] = df_gas_train['WH_WATER_DEPTH_M'].astype(float)\n",
    "df_gas_train['SH_DEPTH_TOP_FT'] = df_gas_train['SH_DEPTH_TOP_FT'].astype(float)\n",
    "df_gas_train['SH_DEPTH_BOT_FT'] = df_gas_train['SH_DEPTH_BOT_FT'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = df_gas_train[coord_cols].corr(method='spearman')\n",
    "\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df_gas_train.columns.values.tolist(), gas_train_cols_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_gas_train.columns:\n",
    "    print(col)\n",
    "    print(df_gas_train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['SH_FORM']:\n",
    "    print(col)\n",
    "    df_gas_train[col] = df_gas_train[col].str.upper()\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in TARGET_COLS:\n",
    "    print(col)\n",
    "    df_gas_train[col] = df_gas_train[col].astype(float)\n",
    "    print(df_gas_train[col].unique(), len(df_gas_train[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for col in TARGET_COLS:\n",
    "    df_gas_train[col].hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_cols = [col for col in df_gas_train.columns if 'DEPTH_REF' not in col and ('DEPTH' in col or 'LAT' in col or 'LONG' in col)]\n",
    "df_gas_train[coord_cols].T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gas_f:\n",
    "    df_gas_groupby[df_gas_groupby['block']=='21/25'].plot(x='date', y=col, style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in PROTO_TARGET_PROD_COLS:\n",
    "    df_prod_groupby[df_prod_groupby['block']=='21/25'].plot(x='date', y=col, style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production.loc[df_production['block']=='21/25', 'PERIODDATE_dt'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['block'] = df_gas_train['WH_BLOCK'].str.extract('(\\d\\d\\/\\d\\d\\w?)')\n",
    "df_gas_train['block'] = df_gas_train['block'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production = pd.read_csv('Production Data/CNS_Field_Production.csv')\n",
    "df_production.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production['block'] = df_production['WELLREGNO'].str.extract('(\\d\\d\\/\\d\\d\\w?)')\n",
    "df_production['block'] = df_production['block'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set(df_gas_train['block'])\n",
    "set_2 = set(df_production['block'])\n",
    "len(set_1), len(set_2), len(set_1.intersection(set_2)), len(set_1 - set_2), len(set_2 - set_1), len(set_1.symmetric_difference(set_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rock = pd.read_csv('Geochemistry Data/CNS rock samples.csv')\n",
    "rock_cols_desc = df_rock.loc[0].values.tolist()\n",
    "df_rock = df_rock[1:].reset_index(drop=True)\n",
    "df_rock.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_rock.columns:\n",
    "    print(col)\n",
    "    print(df_rock[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(df_rock.columns.values.tolist(), rock_cols_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_rock.columns:\n",
    "    try:\n",
    "        if 'DATE' not in col:\n",
    "            print(col)\n",
    "            df_rock[col] = df_rock[col].replace({'World Geodetic System 1984': 'nan',\n",
    "                                                 'WORLD GEODETIC SYSTEM 1984': 'nan'}).astype(float)\n",
    "        else:\n",
    "            df_rock[col] = pd.to_datetime(df_rock[col])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_float_cols = []\n",
    "for col in df_rock.columns:\n",
    "    if df_rock[col].dtype == float:\n",
    "        rock_float_cols += [col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock_filled = df_rock.dropna(how='all', axis=0).groupby(['block']).apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.loc[df_rock['block']=='14/19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in df_rock_filled['block'].unique():\n",
    "    try:\n",
    "        print(block)\n",
    "        df_rock_filled.loc[df_rock_filled['block']==block].plot(x='WH_COMP_DATE', y=rock_float_cols, legend=False, style='.-')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rock_float_cols), df_rock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rock_float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock['block'] = df_rock['WELL_NAME'].str.extract('(\\d\\d\\/\\d\\d\\w?)')\n",
    "df_rock['block'] = df_rock['block'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTO_TARGET_PROD_COLS = [\n",
    "    'OILPRODMAS',\n",
    "    'OILPRODM3',\n",
    "    'OILPRDDENS',\n",
    "    'OILPRODMBD',\n",
    "    'WATPRODMAS',\n",
    "    'WATPRODVOL',\n",
    "    'WATPRODMBD',\n",
    "    'AGASPRODMA',\n",
    "    'AGASPROMMS',\n",
    "    'AGASPROKSM',\n",
    "    'AGASPRODEN',\n",
    "    'DGASPRODMA',\n",
    "    'DGASPROKSM',\n",
    "    'DGASPROMMS',\n",
    "    'DGASPRODEN'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for block in tqdm(df_production['block'].unique()):\n",
    "    print(block)\n",
    "    try:\n",
    "        mask = df_production['block'] == block\n",
    "        df_production.loc[mask, PROTO_TARGET_PROD_COLS] = df_production.loc[mask, PROTO_TARGET_PROD_COLS].interpolate()\n",
    "        df_production.loc[mask].plot(x='date', y=PROTO_TARGET_PROD_COLS, style='.-')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCK_COLS = rock_float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock_filled['WH_COMP_DATE_dt'] = pd.to_datetime(df_rock_filled['WH_COMP_DATE'])\n",
    "df_rock_filled['date'] = pd.to_datetime(df_rock_filled['WH_COMP_DATE_dt'].dt.strftime('%Y-%m'))\n",
    "df_rock_groupby = df_rock_filled.groupby(['block', 'date'])[ROCK_COLS].median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production['PERIODDATE_dt'] = pd.to_datetime(df_production['PERIODDATE'])\n",
    "df_production['date'] = pd.to_datetime(df_production['PERIODDATE_dt'].dt.strftime('%Y-%m'))\n",
    "df_prod_groupby = df_production.groupby(['block', 'date'])[PROTO_TARGET_PROD_COLS].sum().reset_index()\n",
    "# df_prod_groupby['block_dt'] = df_prod_groupby['block'] + '_' + df_prod_groupby['date'].dt.strftime('%Y_%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in gas_f:\n",
    "    df_gas_train[col] = df_gas_train[col].astype(float)\n",
    "    print(df_gas_train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['WH_LONG'] = df_gas_train['WH_LONG'].replace({\"World Geodetic System 1984\":\"nan\"}).astype(float)\n",
    "df_gas_train['WH_LAT'] = df_gas_train['WH_LAT'].replace({\"World Geodetic System 1984\":\"nan\"}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set(df_gas_train['block'])\n",
    "set_2 = set(df_production['block'])\n",
    "len(set_1), len(set_2), len(set_1.intersection(set_2)), len(set_1 - set_2), len(set_2 - set_1), len(set_1.symmetric_difference(set_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set(df_gas_train['block'])\n",
    "set_2 = set(df_rock['block'])\n",
    "len(set_1), len(set_2), len(set_1.intersection(set_2)), len(set_1 - set_2), len(set_2 - set_1), len(set_1.symmetric_difference(set_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock['block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filling = df_gas_train.groupby(['block'])[gas_f + ['WH_LONG', 'WH_LAT']].apply(lambda x: x.fillna(x.mean())).reset_index().drop('level_1', axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filling.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_list = df_filling.set_index('block').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fill_list:\n",
    "    df_gas_train.loc[df_gas_train[col].isnull(),col] = df_gas_train['block'].map(df_filling.set_index('block')[col].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train[df_gas_train['SH_CDATE'].isna()]['GAS_ACQ_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['GAS_ACQ_DATE_dt'] = pd.to_datetime(df_gas_train['GAS_ACQ_DATE'])\n",
    "df_gas_train['date'] = pd.to_datetime(df_gas_train['GAS_ACQ_DATE_dt'].dt.strftime('%Y-%m'))\n",
    "df_gas_groupby = df_gas_train.groupby(['block', 'date'])[gas_f + coord_cols].median().reset_index()\n",
    "# df_gas_groupby['block_dt'] = df_gas_groupby['block'] + '_' + df_gas_groupby['date'].dt.strftime('%Y_%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.groupby(['block']).first().reset_index()['block'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_gas_groupby['block'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gas_groupby = df_gas_groupby.dropna(how='all', axis=1)\n",
    "df_gas_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_groupby.rename({'dt_month_ceil': 'date'}, axis=1, inplace=True)\n",
    "df_gas_groupby.rename({'dt_month_ceil': 'date'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_1 = set(df_gas_groupby['block_dt'])\n",
    "# set_2 = set(df_prod_groupby['block_dt'])\n",
    "# len(set_1), len(set_2), len(set_1.intersection(set_2)), len(set_1 - set_2), len(set_2 - set_1), len(set_1.symmetric_difference(set_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = df_gas_groupby.merge(df_prod_groupby, on=['block', 'date'], how='left')\n",
    "df_master = df_master.sort_values(['block', 'date']).reset_index(drop=True)\n",
    "df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['block'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['date'] = df_gas_train['GAS_ACQ_DATE_dt']\n",
    "df_production['date'] = df_production['PERIODDATE_dt']\n",
    "df_lists = [df_gas_train[['date'] + TARGET_COLS + ['block']], df_production[['date'] + PROTO_TARGET_PROD_COLS + ['block']]]\n",
    "df_anal = pd.concat(df_lists, axis=0, ignore_index=True).sort_values(['block', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production[PROTO_TARGET_PROD_COLS].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train[gas_f].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = df_master.groupby(['block']).groups\n",
    "for key, values in tqdm(groups.items()):\n",
    "    print(key)\n",
    "    data = df_master.iloc[values]\n",
    "    y_cols = gas_f + PROTO_TARGET_PROD_COLS\n",
    "#     data_low = data.loc[data[y_cols] < 10.].dropna(how='all')\n",
    "#     data_mid = data.loc[(data[y_cols] >= 10.) & (data[y_cols] < 1000.)].dropna(how='all')\n",
    "#     data_high = data.loc[data[y_cols] >= 1000.].dropna(how='all')\n",
    "#     for col in TARGET_COLS + PROTO_TARGET_PROD_COLS:\n",
    "#         print(col, data[col].min(), data[col].max(), data[col].std(), data[col].median())\n",
    "#     data_low = data[data[TARGET_COLS + PROTO_TARGET_PROD_COLS]\n",
    "    data.plot(x='date', y=y_cols, style='.-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min_ceiled = pd.to_datetime(df_gas_train['date'].min().strftime('%Y-%m'))\n",
    "date_max_ceiled = pd.to_datetime(df_gas_train['date'].max().strftime('%Y-%m'))\n",
    "date_range = pd.DataFrame({'date': pd.date_range(date_min_ceiled - pd.DateOffset(1), date_max_ceiled, freq='M') + pd.DateOffset(1)})\n",
    "date_min_ceiled, date_max_ceiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min_ceiled, date_max_ceiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master['block'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df_prod_groupby['block'].unique())), len(set(df_gas_groupby['block'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_prod_groupby['block'].unique()).intersection(set(df_gas_groupby['block'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_master['block'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital = pd.DataFrame()\n",
    "df_digital_nan = pd.DataFrame()\n",
    "PROTO_TARGET_PROD_COLS_INTERPOLATED = []\n",
    "for block in tqdm(df_master['block'].unique()):\n",
    "    date_range_copy = date_range.copy(deep=True)\n",
    "    date_range_copy['block'] = block\n",
    "    data_block = date_range_copy.merge(df_prod_groupby[df_prod_groupby['block'] == block], on=['date', 'block'], how='left')\n",
    "    data_block = data_block.merge(df_gas_groupby[df_gas_groupby['block'] == block], on=['date', 'block'], how='left')\n",
    "    df_digital_nan = df_digital_nan.append(data_block, ignore_index=True)\n",
    "    data_block['block'] = data_block['block'].fillna(method='ffill').fillna(method='bfill')\n",
    "    data_block[gas_f] = data_block[gas_f].fillna(method='ffill').fillna(method='bfill')\n",
    "    data_block[['WH_LAT', 'WH_LONG']] = data_block[['WH_LAT', 'WH_LONG']].fillna(method='ffill').fillna(method='bfill')\n",
    "    data_block[PROTO_TARGET_PROD_COLS] = data_block[PROTO_TARGET_PROD_COLS].fillna(0)\n",
    "    \n",
    "    for col in PROTO_TARGET_PROD_COLS:\n",
    "        data_block[col+ '_interpolated'] = data_block[col].interpolate(method='linear')\n",
    "        PROTO_TARGET_PROD_COLS_INTERPOLATED += [col+ '_interpolated']\n",
    "    df_digital = df_digital.append(data_block, ignore_index=True)\n",
    "PROTO_TARGET_PROD_COLS_INTERPOLATED = list(set(PROTO_TARGET_PROD_COLS_INTERPOLATED))\n",
    "df_digital.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in df_digital['block'].unique():\n",
    "    try:\n",
    "        print(block)\n",
    "        df_gas_train[df_gas_train['block']==block].plot(x='date', y=gas_f, style='.-')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in df_digital['block'].unique():\n",
    "    try:\n",
    "        print(block)\n",
    "        df_production[df_production['block']==block].plot(x='date', y=PROTO_TARGET_PROD_COLS, style='.-')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_digital.groupby(['block']).plot(x='date', y=gas_f, style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in tqdm(df_digital['block'].unique()):\n",
    "    df_digital[df_digital['block']==block].plot(x='date', y=PROTO_TARGET_PROD_COLS_INTERPOLATED, style='.-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital.groupby(['block']).plot(x='date', y=PROTO_TARGET_PROD_COLS, style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital_nan.to_csv('df_digital_nan.csv', index=False)\n",
    "df_digital.to_csv('df_digital.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rock_groupby_filled = df_rock_groupby.fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_filled.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_cols_drop = [\n",
    "     'H_INDEX',\n",
    "     'O_INDEX',\n",
    "     'P_INDEX',\n",
    "     'WH_SPUD_YEAR',\n",
    "     'SAMPLE_ID_GM',\n",
    "     'SAMPLE_ID_GDB',\n",
    "     'SAMPLE_ID_SAM',\n",
    "     'EXT_SAMPLE_VENDOR',]\n",
    "\n",
    "ROCK_COLS = [col for col in ROCK_COLS if col not in rock_cols_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCK_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = tsfresh.extract_features(df_rock_groupby_filled[ROCK_COLS + ['block', 'date']],\n",
    "                                 column_id='block',\n",
    "                                 column_sort='date', default_fc_parameters=tsfresh.feature_extraction.settings.MinimalFCParameters())\n",
    "# for col in coord_cols:\n",
    "#     df_ts[col] = df_ts.index.map(df_digital.groupby(['block'])[col].first().to_dict())\n",
    "\n",
    "df_ts = df_ts.replace([np.inf, -np.inf], np.nan)\n",
    "df_ts_filled = df_ts.fillna(-9999)\n",
    "df_ts_filled_fit_tr = sklearn.preprocessing.StandardScaler().fit_transform(df_ts_filled)\n",
    "X_embedded = sklearn.preprocessing.StandardScaler().fit_transform(TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(df_ts_filled_fit_tr))\n",
    "clusterization = KMeans(n_clusters=2, random_state=42)\n",
    "clusterization = clusterization.fit(X_embedded)\n",
    "labels = clusterization.labels_\n",
    "\n",
    "df_X = pd.DataFrame(X_embedded)\n",
    "df_X['labels'] = labels\n",
    "df_X['block'] = df_ts.index\n",
    "df_X = df_X[df_X['block'].isin(df_digital['block'].unique())]\n",
    "plt.scatter(df_X[0], df_X[1], c=df_X['labels'], s=50, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "labels_name = 'rock_labels'\n",
    "df_ts_filled[labels_name] = labels\n",
    "df_rock_groupby_filled[labels_name] = df_rock_groupby_filled['block'].map(df_ts_filled[labels_name].to_dict())\n",
    "labeled_curves = df_rock_groupby_filled.groupby([labels_name, 'date']).mean().reset_index()\n",
    "for label in set(labels):\n",
    "    print(label)\n",
    "    labeled_curves[labeled_curves[labels_name] == label].plot(x='date', y=ROCK_COLS, legend=False)\n",
    "    plt.show()\n",
    "\n",
    "df_labels_coords = df_rock_groupby_filled.groupby(['block'])['WH_LAT', 'WH_LONG', labels_name].first()\n",
    "df_labels_coords = df_labels_coords.loc[df_digital['block'].unique()].dropna()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(x=df_labels_coords['WH_LONG'], y=df_labels_coords['WH_LAT'], c=df_labels_coords[labels_name], s=50, cmap='viridis')\n",
    "\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Labels\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.xlabel(\"WH_LONG\")\n",
    "plt.ylabel(\"WH_LAT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_embedded)\n",
    "df_X['labels'] = labels\n",
    "df_X['block'] = df_ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_coords.to_csv('rock_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_filled.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels), len(df_ts_filled_fit_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('all_model_predicts.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in data.items():\n",
    "    print(key)\n",
    "    for v_key, v_values in values[1].items():\n",
    "        v_values['GAS_CLUSTER'] = v_values.pop('GAS_C21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_model_predicts_with_clusters.pickle', 'wb') as handle:\n",
    "    pickle.dump(data, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).loc[1, 'oil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ts = tsfresh.extract_features(df_digital[gas_f + ['block', 'date']],\n",
    "                                 column_id='block',\n",
    "                                 column_sort='date', default_fc_parameters=tsfresh.feature_extraction.settings.MinimalFCParameters())\n",
    "# for col in coord_cols:\n",
    "#     df_ts[col] = df_ts.index.map(df_digital.groupby(['block'])[col].first().to_dict())\n",
    "\n",
    "df_ts = df_ts.replace([np.inf, -np.inf], np.nan)\n",
    "df_ts_filled = df_ts.fillna(-9999)\n",
    "\n",
    "X_embedded = sklearn.preprocessing.StandardScaler().fit_transform(TSNE(n_components=2, random_state=42, perplexity=30).fit_transform(df_ts_filled))\n",
    "clusterization = KMeans(n_clusters=4, random_state=42)\n",
    "clusterization = clusterization.fit(X_embedded)\n",
    "labels = clusterization.labels_\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=labels, s=50, cmap='viridis')\n",
    "\n",
    "labels_name = 'gas_labels'\n",
    "df_ts[labels_name] = labels\n",
    "df_digital[labels_name] = df_digital['block'].map(df_ts[labels_name].to_dict())\n",
    "labeled_curves = df_digital.groupby([labels_name, 'date']).mean().reset_index()\n",
    "for label in set(labels):\n",
    "    labeled_curves[labeled_curves[labels_name] == label].plot(x='date', y=gas_f, legend=False)\n",
    "    plt.show()\n",
    "\n",
    "df_labels_coords = df_digital.groupby(['block'])['WH_LAT', 'WH_LONG', labels_name].first()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(x=df_labels_coords['WH_LONG'], y=df_labels_coords['WH_LAT'], c=df_labels_coords[labels_name], s=50, cmap='viridis')\n",
    "\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Labels\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "plt.xlabel(\"WH_LONG\")\n",
    "plt.ylabel(\"WH_LAT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_coords.to_csv('gas_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ts = tsfresh.extract_features(df_digital[PROTO_TARGET_PROD_COLS_INTERPOLATED + ['block', 'date']],\n",
    "                                 column_id='block',\n",
    "                                 column_sort='date', default_fc_parameters=tsfresh.feature_extraction.settings.MinimalFCParameters())\n",
    "# for col in coord_cols:\n",
    "#     df_ts[col] = df_ts.index.map(df_digital.groupby(['block'])[col].first().to_dict())\n",
    "\n",
    "df_ts = df_ts.replace([np.inf, -np.inf], np.nan)\n",
    "df_ts_filled = df_ts.fillna(-9999)\n",
    "\n",
    "X_embedded = sklearn.preprocessing.StandardScaler().fit_transform(TSNE(n_components=2, random_state=42, perplexity=10).fit_transform(df_ts_filled))\n",
    "clusterization = KMeans(n_clusters=4, random_state=42)\n",
    "clusterization = clusterization.fit(X_embedded)\n",
    "labels = clusterization.labels_\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=labels, s=50, cmap='viridis')\n",
    "plt.show()\n",
    "labels_name = 'prod_labels'\n",
    "df_ts[labels_name] = labels\n",
    "df_digital[labels_name] = df_digital['block'].map(df_ts[labels_name].to_dict())\n",
    "labeled_curves = df_digital.groupby([labels_name, 'date']).mean().reset_index()\n",
    "for label in set(labels):\n",
    "    print(label)\n",
    "    labeled_curves[labeled_curves[labels_name] == label].plot(x='date', y=PROTO_TARGET_PROD_COLS, legend=False)\n",
    "    plt.show()\n",
    "\n",
    "df_labels_coords = df_digital.groupby(['block'])['WH_LAT', 'WH_LONG', labels_name].first()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(x=df_labels_coords['WH_LONG'], y=df_labels_coords['WH_LAT'], c=df_labels_coords[labels_name], s=50, cmap='viridis')\n",
    "\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Labels\")\n",
    "ax.add_artist(legend1)\n",
    "plt.xlabel(\"WH_LONG\")\n",
    "plt.ylabel(\"WH_LAT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_coords.to_csv('prod_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in coord_cols:\n",
    "    df_ts[col] = df_ts.index.map(df_digital.groupby(['block'])[col].first().to_dict())\n",
    "\n",
    "df_ts = df_ts.replace([np.inf, -np.inf], np.nan)\n",
    "df_ts_filled = df_ts.fillna(-9999)\n",
    "\n",
    "X_embedded = sklearn.preprocessing.StandardScaler().fit_transform(TSNE(n_components=2, random_state=42, perplexity=10).fit_transform(df_ts_filled[coord_cols]))\n",
    "clusterization = KMeans(n_clusters=3, random_state=42)\n",
    "clusterization = clusterization.fit(X_embedded)\n",
    "labels = clusterization.labels_\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=labels, s=50, cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "labels_name = 'coord_labels'\n",
    "df_ts[labels_name] = labels\n",
    "df_digital[labels_name] = df_digital['block'].map(df_ts[labels_name].to_dict())\n",
    "labeled_curves = df_digital.groupby([labels_name, 'date']).mean().reset_index()\n",
    "for label in set(labels):\n",
    "    print(label)\n",
    "    labeled_curves[labeled_curves[labels_name] == label].plot(x='date', y=PROTO_TARGET_PROD_COLS, legend=False)\n",
    "    plt.show()\n",
    "\n",
    "df_labels_coords = df_digital.groupby(['block'])['WH_LAT', 'WH_LONG', labels_name].first()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(df_labels_coords['WH_LAT'], df_labels_coords['WH_LONG'], c=df_labels_coords[labels_name], s=50, cmap='viridis')\n",
    "\n",
    "# produce a legend with the unique colors from the scatter\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Labels\")\n",
    "ax.add_artist(legend1)\n",
    "plt.xlabel(\"WH_LAT\")\n",
    "plt.ylabel(\"WH_LONG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_coords.to_csv('coord_labels.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df_ts.replace([np.inf, -np.inf], np.nan)\n",
    "df_ts_filled = df_ts.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_filled.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['WH_LAT', 'WH_LONG']:\n",
    "    df_ts_filled[col] = df_ts_filled.index.map(df_digital.groupby(['block'])[col].first().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_embedded = TSNE(n_components=2, random_state=42, perplexity=20.0, metric='canberra').fit_transform(sklearn.preprocessing.StandardScaler().fit_transform(df_ts_filled))\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans = kmeans.fit(X_embedded)\n",
    "labels = kmeans.labels_\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1], c=labels, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['WH_LAT', 'WH_LONG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital['labels'] = df_digital['block'].map(df_ts['labels'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labeled_curves = df_digital.groupby(['labels', 'date']).mean().reset_index()\n",
    "for label in set(labels):\n",
    "    labeled_curves[labeled_curves['labels'] == label].plot(x='date', y=PROTO_TARGET_PROD_COLS, legend=False)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_coords = df_digital.groupby(['block'])['WH_LAT', 'WH_LONG', 'labels'].first()\n",
    "df_labels_coords.plot(x='WH_LAT', y='WH_LONG', kind='scatter', c=df_labels_coords.labels, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts.groupby(['labels']).agg(['median', 'std', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block[PROTO_TARGET_PROD_COLS] = data_block[PROTO_TARGET_PROD_COLS].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block[gas_f].fillna('ffill').fillna('bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital.plot(x='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf[buf['date'] == data_block.loc[0, 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df_master['dt_month_ceil'].min().strftime('%Y-%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for block in tqdm(df_anal['block'].unique()):\n",
    "    print(block)\n",
    "    data = df_anal[df_anal['block'] == block]\n",
    "    if len(data) > 10:\n",
    "        df_block = df_anal[df_anal['block'] == block]\n",
    "        df_block\n",
    "        df_block.plot(x='date', y=PROTO_TARGET_PROD_COLS, style='.-')\n",
    "        df_block.plot(x='date', y=TARGET_COLS, style='.-')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('plot canceled: len < 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import seaborn as sns\n",
    "\n",
    "combos_cols = list(product(TARGET_COLS, PROTO_TARGET_PROD_COLS))\n",
    "\n",
    "corr = df_master[TARGET_COLS+ PROTO_TARGET_PROD_COLS].corr(method='spearman')\n",
    "\n",
    "\n",
    "# plot the heatmap\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_master.groupby(['block_x']).plot(x='dt_month_ceil', y=['AGASPRODMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col, df_gas_train[col].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(coord_cols):\n",
    "    print(col)\n",
    "    try:\n",
    "        df_gas_train[col] = df_gas_train[col].replace({'World Geodetic System 1984': float('nan')}).astype(float)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axes3D\n",
    "# %matplotlib notebook\n",
    "_3d = df_gas_train[['WH_LAT', 'WH_LONG', 'SH_DEPTH_TOP_FT']].dropna()\n",
    "x = np.array(_3d['WH_LAT'].values, dtype=float)\n",
    "y = np.array(_3d['WH_LONG'].values, dtype=float)\n",
    "z = np.array(_3d['SH_DEPTH_TOP_FT'].values, dtype=float)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "\n",
    "ax.plot_trisurf(x, y, z, linewidth=0.2, cmap='hot')\n",
    "ax.scatter(x, y, z, c='g', s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data formatting\n",
    "for col in df_gas_train.columns:\n",
    "    if 'DATE' in col:\n",
    "        df_gas_train[col] = pd.to_datetime(df_gas_train[col])\n",
    "df_gas_train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types check\n",
    "for col in df_gas_train.columns:\n",
    "    print(df_gas_train[col].dtype, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_cols(df, prefix='DATE'):\n",
    "    return [col for col in df.columns if prefix in col]\n",
    "\n",
    "def get_cols_by_dtype(df, dtype=float):\n",
    "    return [col for col in df.columns if df[col].dtype==dtype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "date_cols = get_date_cols(df_gas_train)\n",
    "float_cols = get_cols_by_dtype(df_gas_train)\n",
    "groupby_cols = ['WH_LAT', 'WH_LONG']\n",
    "groupby = df_gas_train.groupby(groupby_cols)\n",
    "for date_col in date_cols:\n",
    "#     for float_col in float_cols:\n",
    "#         df_gas_train.plot(x=date_col, y=float_col)\n",
    "#         plt.show()\n",
    "    groupby[list(set(float_cols) - set(groupby_cols)) + [date_col]].plot(x=date_col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.sort_values(['SH_CDATE'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date analysis\n",
    "for date_col in date_cols:\n",
    "    print(date_col, df_gas_train[date_col].min(), df_gas_train[date_col].max())\n",
    "    print(df_gas_train[date_col].diff().mean(), df_gas_train[date_col].diff().median(), df_gas_train[date_col].diff().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train['SH_FORM'] = df_gas_train['SH_FORM'].replace({'VALHALL': 'VALLHALL',\n",
    "                                                           'VALHAL': 'VALLHALL',\n",
    "                                                           'VALLHAL': 'VALLHALL',\n",
    "                                                           'VALHALL CLAY': 'VALLHALL CLAY'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make data for plot 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cond = ['WELL_NAME', 'SH_FORM', pd.Grouper(key='SH_CDATE', freq='1D')]\n",
    "get_cols = ['WH_LAT', 'WH_LONG', 'SH_DEPTH_TOP_FT', *TARGET_COLS]\n",
    "groupby = df_gas_train.groupby(groupby_cond)\n",
    "df_for_2d_plot = df_gas_train.groupby(groupby_cond)[get_cols].median().reset_index()\n",
    "df_for_2d_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_2d_plot['SH_FORM'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_for_2d_plot['SH_FORM'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_2d_plot.loc[df_for_2d_plot['SH_FORM'] == 'VALLHALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_for_2d_plot['WELL_NAME'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_2d_plot.groupby(['SH_FORM', pd.Grouper(key='SH_CDATE', freq='1D')]).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_tricks as json\n",
    "d_coords = {}\n",
    "for form in df_gas_train['SH_FORM'].unique():\n",
    "    try:\n",
    "        mask = df_gas_train['SH_FORM'] == form\n",
    "        print(form)\n",
    "        print(df_gas_train.loc[mask, ['WH_LAT', 'WH_LONG']]['WH_LAT'].unique())\n",
    "        print(df_gas_train.loc[mask, ['WH_LAT', 'WH_LONG']]['WH_LONG'].unique())\n",
    "        print('WELLS')\n",
    "        coords = list(df_gas_train.loc[mask].groupby(['WH_LAT', 'WH_LONG']).groups.keys())\n",
    "        lat = [el[0] for el in coords if el[0] != float('nan')]\n",
    "        long = [el[1] for el in coords if el[1] != float('nan')]\n",
    "        d_coords[str(form)] =  coords\n",
    "        print(coords)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "json.dumps(d_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_gas_train['SH_FORM'] == 'HOD'\n",
    "df_gas_train.loc[mask, ['WH_LAT', 'WH_LONG']]['WH_LAT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas_train.loc[mask, ['WH_LAT', 'WH_LONG']]['WH_LONG'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gas_train.loc[mask].groupby(['WH_LAT', 'WH_LONG', 'SH_DEPTH_TOP_FT', 'SH_DEPTH_BOT_FT']).plot(x='SH_CDATE', y=TARGET_COLS, style='.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_gas_point = {}\n",
    "for key, value in tqdm(df_for_2d_plot.groupby(['SH_FORM']).groups.items()):\n",
    "    data = df_for_2d_plot.loc[value]\n",
    "    print(key, len(data))\n",
    "    stats_gas_point[key] = len(data)\n",
    "    data[['WH_LAT', 'WH_LONG']].plot(x='WH_LAT', y='WH_LONG', kind='scatter')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_gas_point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine_venv",
   "language": "python",
   "name": "engine_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
